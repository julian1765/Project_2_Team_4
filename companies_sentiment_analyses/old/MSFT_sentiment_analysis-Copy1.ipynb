{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the closing prices of Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-10-20</th>\n",
       "      <td>26.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-21</th>\n",
       "      <td>26.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-22</th>\n",
       "      <td>26.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-23</th>\n",
       "      <td>28.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-26</th>\n",
       "      <td>28.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            close\n",
       "2009-10-20  26.37\n",
       "2009-10-21  26.61\n",
       "2009-10-22  26.59\n",
       "2009-10-23  28.03\n",
       "2009-10-26  28.69"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "%matplotlib inline\n",
    "\n",
    "# Load .env environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Create the Alpaca API object\n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")\n",
    "\n",
    "# Format current date as ISO format\n",
    "start_date = pd.Timestamp(\"2009-10-20\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2021-01-21\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Set the tickers\n",
    "ticker = \"MSFT\"\n",
    "\n",
    "# Set timeframe to one day ('1D') for the Alpaca API\n",
    "timeframe = \"1D\"\n",
    "\n",
    "# Get current closing prices\n",
    "df_closing_prices = alpaca.get_barset(\n",
    "    ticker,\n",
    "    timeframe,\n",
    "    start = start_date,\n",
    "    end = end_date\n",
    ").df\n",
    "\n",
    "# Dissolve multiindex and fetch the closing prices \n",
    "df_closing_prices = df_closing_prices.droplevel(0, axis=1)[['close']]\n",
    "\n",
    "# Drop the time component of the date\n",
    "df_closing_prices.index = df_closing_prices.index.date\n",
    "\n",
    "# Display sample data\n",
    "df_closing_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-10-21</th>\n",
       "      <td>26.61</td>\n",
       "      <td>0.009101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-22</th>\n",
       "      <td>26.59</td>\n",
       "      <td>-0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-23</th>\n",
       "      <td>28.03</td>\n",
       "      <td>0.054156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-26</th>\n",
       "      <td>28.69</td>\n",
       "      <td>0.023546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-27</th>\n",
       "      <td>28.61</td>\n",
       "      <td>-0.002788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            close    return\n",
       "2009-10-21  26.61  0.009101\n",
       "2009-10-22  26.59 -0.000752\n",
       "2009-10-23  28.03  0.054156\n",
       "2009-10-26  28.69  0.023546\n",
       "2009-10-27  28.61 -0.002788"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_closing_prices['return'] = df_closing_prices['close'].pct_change()\n",
    "df_closing_prices.dropna(inplace=True)\n",
    "df_closing_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data of google research results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342938\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-21 20:00:01</th>\n",
       "      <td>Microsoft Edge for Linux: Pros and cons  https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21 20:00:01</th>\n",
       "      <td>#VIDEOJUEGOS | Lista completa de los juegos op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21 20:00:03</th>\n",
       "      <td>\"“Back then, Google claimed Microsoft’s practi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21 20:00:03</th>\n",
       "      <td>Microsoft libera Windows 10 October 2020 Updat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-21 20:00:04</th>\n",
       "      <td>I understand that java won't be irrelevant tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 tweet\n",
       "2020-10-21 20:00:01  Microsoft Edge for Linux: Pros and cons  https...\n",
       "2020-10-21 20:00:01  #VIDEOJUEGOS | Lista completa de los juegos op...\n",
       "2020-10-21 20:00:03  \"“Back then, Google claimed Microsoft’s practi...\n",
       "2020-10-21 20:00:03  Microsoft libera Windows 10 October 2020 Updat...\n",
       "2020-10-21 20:00:04  I understand that java won't be irrelevant tha..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import calendar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "file_path = Path(\"../companies_tweet_data_3months/microsoft.csv\")\n",
    "news_df = pd.read_csv(file_path, parse_dates=[['date','time']], infer_datetime_format=True, usecols=['date',\"tweet\",'time'])\n",
    "\n",
    "# Delete the index label and sort in ascending order\n",
    "news_df.set_index('date_time', inplace=True)\n",
    "news_df.index.name = None\n",
    "news_df.sort_index(axis=0, inplace=True)\n",
    "\n",
    "# Display sample data\n",
    "print(len(news_df))\n",
    "display(news_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>Historische Ereignisse am 22. Oktober 1968 (vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>Automatic Removal of Sensitive Data | Microsof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>love how our Microsoft Research Team leads the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>Una de las cosas que más orgullo me produce de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>Code Read Dyslexia Network Australia Ltd &amp;amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        tweet\n",
       "2020-10-22  Historische Ereignisse am 22. Oktober 1968 (vo...\n",
       "2020-10-22  Automatic Removal of Sensitive Data | Microsof...\n",
       "2020-10-22  love how our Microsoft Research Team leads the...\n",
       "2020-10-22  Una de las cosas que más orgullo me produce de...\n",
       "2020-10-22  Code Read Dyslexia Network Australia Ltd &amp;..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop news published after 4pm since it does not affect the closing price of that day\n",
    "news_df = news_df.between_time('00:00:00','15:59:59', include_end=False)\n",
    "\n",
    "# Drop time in the index labels\n",
    "news_df.index = news_df.index.date\n",
    "\n",
    "# Display sample data\n",
    "print(len(news_df))\n",
    "display(news_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\kn_na\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download/Update the VADER Lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 83.0 GiB for an array with shape (11143167098,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-474b39ac5266>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Reorder DataFrame columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mnews_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiments_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mnews_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   7206\u001b[0m         \u001b[1;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7207\u001b[0m         \"\"\"\n\u001b[1;32m-> 7208\u001b[1;33m         return self._join_compat(\n\u001b[0m\u001b[0;32m   7209\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7210\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   7222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7224\u001b[1;33m             return merge(\n\u001b[0m\u001b[0;32m   7225\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7226\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[0mldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_index\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"asof\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 849\u001b[1;33m             join_index, left_indexer, right_indexer = left_ax.join(\n\u001b[0m\u001b[0;32m    850\u001b[0m                 \u001b[0mright_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m   3298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3299\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3300\u001b[1;33m             return self._join_non_unique(\n\u001b[0m\u001b[0;32m   3301\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3302\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_join_non_unique\u001b[1;34m(self, other, how, return_indexers)\u001b[0m\n\u001b[0;32m   3425\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3427\u001b[1;33m         left_idx, right_idx = _get_join_indexers(\n\u001b[0m\u001b[0;32m   3428\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3429\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[0mjoin_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_join_functions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjoin_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\join.pyx\u001b[0m in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 83.0 GiB for an array with shape (11143167098,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Create the Facebook Libra sentiment scores DataFrame\n",
    "sentiments = []\n",
    "\n",
    "for title in news_df[\"tweet\"]:\n",
    "    try:\n",
    "        sentiment = analyzer.polarity_scores(title) # get sentiment score\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        sentiments.append({\"compound\": compound,\n",
    "                                 \"positive\": pos,\n",
    "                                 \"negative\": neg,\n",
    "                                 \"neutral\": neu\n",
    "                                })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "sentiments_df = pd.DataFrame(sentiments, index=news_df.index)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "news_df = news_df.join(sentiments_df)\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_score_df = pd.DataFrame(index=news_df.index)\n",
    "# sentiment_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average of compound scores for a day with more than 1 article\n",
    "import numpy as np\n",
    "# sentiment_score_df = news_df.groupby(level=0)[['compound']].agg([('avg_sentiment',np.mean), ('article_counts',count)])\n",
    "sentiment_score_df = news_df.groupby(level=0)[['compound']].count()\n",
    "sentiment_score_df[\"avg_sentiments\"] = news_df.groupby(level=0)[['compound']].mean()\n",
    "sentiment_score_df.rename(columns= {'compound':\"article_counts\"}, inplace=True)\n",
    "sentiment_score_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the DFs of closing prices and sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate\n",
    "df = pd.concat([df_closing_prices, sentiment_score_df], axis=1, join='inner')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = df[\"return\"].apply(lambda x: 1 if x >= 0.01 else (0 if -0.01<x<0.01 else -1))\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(df[['article_counts','avg_sentiments']], df['class'], \n",
    "                             test_size=0.2,\n",
    "                             random_state=1,\n",
    "                             stratify=df['class']\n",
    "                            )\n",
    "\n",
    "X_train = X_train.values.reshape(-1,2)\n",
    "X_test = X_test.values.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing and fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the five models and choose the best one\n",
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=1)\n",
    "\n",
    "# Support vector machine\n",
    "from sklearn.svm import SVC\n",
    "algorithm2 = SVC(kernel='rbf', random_state=1)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm3 = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm4 = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "algorithm5 = XGBClassifier(random_state=1)\n",
    "\n",
    "# Create a list of the five model instances\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, algorithm5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of the five models\n",
    "for algorithm in algorithms:\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    score = algorithm.score(X_test, y_test)\n",
    "    name = algorithm.__class__.__name__\n",
    "    \n",
    "    print(f'{name} score: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the five model instances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algorithm1 = LogisticRegression(random_state=1)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "algorithm2 = SVC(kernel='rbf', gamma=\"scale\", C=1, random_state=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algorithm3 = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algorithm4 = RandomForestClassifier(random_state=1)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "algorithm5 = XGBClassifier(random_state=1)\n",
    "\n",
    "algorithms = [algorithm1, algorithm2, algorithm3, algorithm4, algorithm5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of the five models\n",
    "\n",
    "# Create a balanced set of samples, create a StratifiedKFold instance\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    # Conduct cross validation for each one of the five models\n",
    "    scores = cross_val_score(algorithm, X_train, y_train, cv=stratifiedkfold)\n",
    "    score = scores.mean()\n",
    "    name = algorithm.__class__.__name__\n",
    "    print(f'{name} average score: {score:.4f} / each score: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the parameters\n",
    "params = {'C':[1, 10, 100, 1000, 10000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
    "algorithm = SVC(random_state=1)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=3)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(algorithm, params, cv=stratifiedkfold)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Based on the best parameters, predict y values from test data\n",
    "best = gs.best_estimator_\n",
    "best_pred = best.predict(X_test)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "score = best.score(X_test, y_test)\n",
    "print(f'score: {score:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "x",
   "language": "python",
   "name": "x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
