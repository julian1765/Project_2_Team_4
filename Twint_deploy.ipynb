{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mike4\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initial Imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import regex as re\n",
    "import nltk\n",
    "from datetime import date\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "nltk.download('stopwords')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Initialize set of inputs\n",
    "# List of Stocks\n",
    "stocks = ['microsoft','sony','pfizer','regeneron','moderna']\n",
    "\n",
    "# Set up Date range\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "today = datetime.date.today()\n",
    "end_time = today.strftime('%Y-%m-%d %H:%M:%S')\n",
    "start_time = today - relativedelta(years=1)\n",
    "start_time = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data_crawlers function\n",
    "stock_df = pd.DataFrame()\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_crawlers(stock):\n",
    "    c = twint.Config()\n",
    "    c.Search = stock\n",
    "    c.Hide_output = True\n",
    "    c.Limit = 1000 \n",
    "    #c.Store_csv = True\n",
    "    c.Since = start_time\n",
    "    c.Until = end_time\n",
    "    #c.Output = f\"{stock}.csv\"\n",
    "    c.Pandas = True\n",
    "    c.Pandas_au = True\n",
    "    twint.run.Search(c)\n",
    "    #df = twint.storage.panda.Tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n",
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n",
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n",
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n",
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 1.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 8.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 27.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 64.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 125.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 216.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 343.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 512.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "sleeping for 729.0 secs\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n",
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!"
     ]
    }
   ],
   "source": [
    "# Deploy data_crawlers function on stocks list\n",
    "for i in stocks: \n",
    "    data_crawlers(i)\n",
    "    df = twint.storage.panda.Tweets_df\n",
    "    stock_df = stock_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df = stock_df.reset_index(drop=True)\n",
    "stock_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to read in csv\n",
    "from pathlib import Path\n",
    "def csv_import(stock):\n",
    "    stock_path = Path(f'{stock}.csv')\n",
    "    return stock_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'microsoft.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ec8145c744d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mx_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mi_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\envs\\nlpenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\nlpenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\nlpenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\nlpenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\nlpenv\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'microsoft.csv'"
     ]
    }
   ],
   "source": [
    "path_list = []\n",
    "for i in stocks:\n",
    "    i_df = pd.DataFrame()\n",
    "    path_list.append(csv_import(i))\n",
    "    for x in path_list: \n",
    "        x_df = pd.DataFrame()\n",
    "        i_df = pd.read_csv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_import('microsoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlpenv]",
   "language": "python",
   "name": "conda-env-nlpenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
